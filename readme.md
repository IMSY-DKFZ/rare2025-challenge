# Rare Challenge 2025
The repository for the IMSY team participating in the [Rare25 Challenge (MICCAI 2025)](https://rare25.grand-challenge.org/).

The structure of this repo was based on the [example challenge submission repository](https://github.com/TUE-VCA/RARE25-Submission) provided by the challenge organisers.

# 1- Environment set up

* First, clone the repository and create a new environment:
```
conda create -n rare python=3.12.0
```
* Next, activate the env, cd to the repo folder and install the requirements.txt file
```
pip install -r requirements.txt
```

# 2- Dataset

## Raw data
The dataset can be downloaded from [here](https://huggingface.co/datasets/TimJaspersTue/RARE25-train) or using huggingface-cli:
```
pip install huggingface_hub[cli]
huggingface-cli download TimJaspersTue/RARE25-train --repo-type dataset --local_dir <location>
```

Please place it in the `data/train` directory.

## Data splits
We provide a couple common dataset splits to be used in development. The csv files defining the splits can be found on the network drive in `data/splits`.
* 5 fold cross validation: `5fold_cv.csv`
* Train on Center 1, test on Center 2: `center1_train_center2_test.csv`
* Train on Center 2, test on Center 1: `center2_train_center1_test.csv`
* 5 fold cross-validation with a separate test set: `holdout_cv.csv`


Each file has the following columns: 
* `image_path`: path to the image in the `train` directory.
* `sample_id`: unique image identifier (file name).
* `center`: center number
* `class_name`: `ndbe` for non-dysplastic Barrett's Esophagus, `neo` for Neoplasia
* `target`: class id 0 for non-dysplastic Barrett's Esophagus, 1 for Neoplasia
* `split`: string defining in which split the image is.

The splits can also be generated by running:
```
python data_splitting/create_splits.py
```
This expects a copy of the training data in `data` direcotry.

# 3- Training

`python -m training/train` runs our training pipeline with the parameters specified in `training/config.py`.

In order to train the [GastroNet](https://huggingface.co/tgwboers/GastroNet-5M_Pretrained_Weights) and [DINOv3](https://github.com/facebookresearch/dinov3) models, one needs to request access to the pre-trained weights in the respective repos. Place the Dinov3 ViT-L weights in `resources`.

Our training scripts use wandb for logging, log in to your wandb account before running them.

The training pipeline accesses the GastroNet weights through huggingface. Please log in to huggingface via `huggingface-cli login`.

To reproduce our training runs used for the final challenge submission, run `./reproduce_runs.sh`. The weight-path variable needs to be replaced with Dinov3 ViT-L weights you downloaded.

After everything ran through successfully, the next step is recalibration:

# 4- Re-calibration

Run `python training/recalibrate_files.py` to compute the recalibration parameters.

# 5- Weight extraction

For minimizing latency and memory usage we have to run `python extract_lora_weights.py` which runs through the trained models and separates frozen base weights of dino from the added lora weights (which are different across the single models).

# 6- Submission docker creation

For the use of the DINOv3 models in the final submission docker one needs to first clone the DINOv3 repo and then build the docker:
1. Clone the DINOv3 repository into the base directory here, ideally name it `dino_repo`. You can use the following call: `git clone https://github.com/facebookresearch/dinov3.git dino_repo` 
2. Copy relevant checkpoint folders (`vitl`and `resnet`) as they are to the `resources` directory. For ResNet go through the directories `top1`through `top4` and pull the contents of the subfolder up one level. Now the checkpoints (as well as calibration files and such) should be directly below `topX`.
2. Run `./do_test_run.sh` to verify the submission runs correctly.
3. Run `./do_save.sh` to save the docker image to be submitted to the challenge leaderboard.

## Team members:
Piotr Kalinowski, Dominik Michael, Amine Yamlahi, Berit Pauls, Lucas Luttner, Patrick Godau, Lena Maier-Hein
